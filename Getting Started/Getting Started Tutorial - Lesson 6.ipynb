{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://www.quantopian.com/tutorials/getting-started#lesson6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing in Algorithms\n",
    "\n",
    "The next step will be to integrate the data pipeline we built in Research into our algorithm. One important distinction from Research is that during a backtest our pipeline will be executed each day as the simulation progresses, so we won't need to include start_date and end_date arguments.\n",
    "\n",
    "In order to use our data pipeline in our algorithm, the first step is to add a reference to it in our algorithm's initialize function. This is done using the attach_pipeline method, which requires two inputs: a reference to our Pipeline object (which we construct using make_pipeline), and a String name to identify it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Algorithm API functions\n",
    "from quantopian.algorithm import attach_pipeline\n",
    "\n",
    "\n",
    "def initialize(context):\n",
    "    # Attach pipeline to algorithm\n",
    "    attach_pipeline(\n",
    "        make_pipeline(),\n",
    "        'data_pipe'\n",
    "    )\n",
    "\n",
    "    # Schedule rebalance function\n",
    "    schedule_function(\n",
    "        rebalance,\n",
    "        date_rule=date_rules.week_start(),\n",
    "        time_rule=time_rules.market_open()\n",
    "    )\n",
    "\n",
    "\n",
    "def before_trading_start(context, data):\n",
    "    pass\n",
    "\n",
    "\n",
    "def rebalance(context, data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, our pipeline will process data streams and generate an output before the market opens each day. We can get our pipeline's output in before_trading_start using the pipeline_output function, which takes the pipeline name we specified in initialize, and returns the pandas DataFrame generated by our pipeline. For now we can use our rebalance function to log the top 10 rows from our pipeline's output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Algorithm API functions\n",
    "from quantopian.algorithm import (\n",
    "    attach_pipeline,\n",
    "    pipeline_output,\n",
    ")\n",
    "\n",
    "\n",
    "def initialize(context):\n",
    "    # Attach pipeline to algorithm\n",
    "    attach_pipeline(\n",
    "        make_pipeline(),\n",
    "        'data_pipe'\n",
    "    )\n",
    "\n",
    "    # Schedule rebalance function\n",
    "    schedule_function(\n",
    "        rebalance,\n",
    "        date_rule=date_rules.week_start(),\n",
    "        time_rule=time_rules.market_open()\n",
    "    )\n",
    "\n",
    "# this is new!!!\n",
    "def before_trading_start(context, data):\n",
    "    # Get pipeline output and\n",
    "    # store it in context\n",
    "    context.output = pipeline_output(\n",
    "        'data_pipe'\n",
    "    )\n",
    "\n",
    "# this is new!!!\n",
    "def rebalance(context, data):\n",
    "    # Display first 10 rows\n",
    "    # of pipeline output\n",
    "    log.info(context.output.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add the make_pipeline function we built in Research to our algorithm. Instead of limiting the number of assets like we did for our analysis, our algorithm should consider all assets in the trading universe for which it has a sentiment score. For this we can use the notnull method of our sentiment_score output to create a filter, and get its intersection with the tradable universe using the & operator: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Algorithm API functions\n",
    "from quantopian.algorithm import (\n",
    "    attach_pipeline,\n",
    "    pipeline_output,\n",
    ")\n",
    "\n",
    "# Pipeline imports\n",
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.pipeline.data.psychsignal import stocktwits #this is like a sentiment thing??\n",
    "from quantopian.pipeline.factors import SimpleMovingAverage\n",
    "from quantopian.pipeline.filters import QTradableStocksUS\n",
    "\n",
    "\n",
    "def initialize(context):\n",
    "    # Attach pipeline to algorithm\n",
    "    attach_pipeline(\n",
    "        make_pipeline(),\n",
    "        'data_pipe'\n",
    "    )\n",
    "\n",
    "    # Schedule rebalance function\n",
    "    schedule_function(\n",
    "        rebalance,\n",
    "        date_rule=date_rules.week_start(),\n",
    "        time_rule=time_rules.market_open()\n",
    "    )\n",
    "\n",
    "\n",
    "def before_trading_start(context, data):\n",
    "    # Get pipeline output and\n",
    "    # store it in context\n",
    "    context.output = pipeline_output('data_pipe')\n",
    "\n",
    "\n",
    "def rebalance(context, data):\n",
    "    # Display first 10 rows\n",
    "    # of pipeline output\n",
    "    log.info(context.output.head(10))\n",
    "\n",
    "# this is new!!!\n",
    "# Pipeline definition\n",
    "def make_pipeline():\n",
    "\n",
    "    base_universe = QTradableStocksUS()\n",
    "\n",
    "    sentiment_score = SimpleMovingAverage(\n",
    "        inputs=[stocktwits.bull_minus_bear],\n",
    "        window_length=3,\n",
    "    )\n",
    "\n",
    "    return Pipeline(\n",
    "        columns={\n",
    "            'sentiment_score': sentiment_score,\n",
    "        },\n",
    "        screen=(\n",
    "            base_universe\n",
    "            & sentiment_score.notnull()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm now selects a tradable universe of assets each day, and produces sentiment data we can use to determine asset allocation within our portfolio. In the next lesson we will learn how to construct an optimal portfolio based on the sentiment scores generated by our data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
